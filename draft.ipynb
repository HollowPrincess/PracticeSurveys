{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from dataPreparation import dataPreparation\n",
    "from calculations import assessmentsProcessing\n",
    "#from visualization import assessmentsPage\n",
    "    \n",
    "#settings\n",
    "\n",
    "isFileNeedToBeDownloaded=False \n",
    "minimumSampleSize=10-1\n",
    "avgErr=0.25 #отклонение среднего значения \n",
    "    \n",
    "os.chdir('surveys')\n",
    "df = pd.read_csv('surveys.csv', sep=',', encoding='utf-8', \n",
    "                 parse_dates=['Отметка времени'], \n",
    "                 dayfirst=True)\n",
    "\n",
    "surveysCounter=df.shape[0]\n",
    "\n",
    "df=dataPreparation.dataPreparation(df) #if a survey was changed this function need to be fixed\n",
    "\n",
    "coursePortrait=assessmentsProcessing.assessmentsProcessing(df,avgErr,minimumSampleSize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "textFields=[]\n",
    "for column in df.columns:\n",
    "    if column.split(' ')[0]=='мнение':\n",
    "        textFields.append(column)\n",
    "textFields.append('предложения')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(lowercase=True,ngram_range=(2, 2),stop_words=['russian','english','chinese','japanese','arabic']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pymorphy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport pymorphy2\\nmorph = pymorphy2.MorphAnalyzer()\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from __future__ import print_function\n",
    "#from time import time\n",
    "\n",
    "#from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "#from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "\n",
    "#n_samples = 2000\n",
    "#n_features = 1000\n",
    "n_components = 3\n",
    "n_top_words = 10\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        message = \"\\n \"\n",
    "        message += \" \".join([feature_names[i]+'/'\n",
    "                             for i in topic.argsort()[:-n_top_words - 1:-1]])        \n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "nmftime=0\n",
    "ldatime=0\n",
    "svdtime=0\n",
    "\"\"\"\n",
    "textres=pd.DataFrame(columns=['курс','поле','количество отзывов','темы'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for textField in textFields:\n",
    "    frames = [df['курс'],df[textField]]\n",
    "    textCorpus = pd.concat(frames,axis=1)\n",
    "    textCorpus = textCorpus.dropna()\n",
    "    \n",
    "    tfidf_vectorizer.fit(textCorpus[textField])\n",
    "    textVecs=tfidf_vectorizer.transform(textCorpus[textField])\n",
    "    \n",
    "    \n",
    "    for course in coursePortrait['курс']:\n",
    "        currentTextCorpus=textCorpus.loc[textCorpus['курс'] == course][textField]\n",
    "        responsesNum=currentTextCorpus.shape[0]\n",
    "        \n",
    "        if responsesNum>3:\n",
    "            \"\"\"\n",
    "            newCorpus=[]\n",
    "            tmpCorpus=[]\n",
    "            for response in currentTextCorpus:\n",
    "                for word in response.split(' '):\n",
    "                    tmpCorpus.append(morph.parse(word)[0].normal_form)\n",
    "            newCorpus.append(\" \".join(map(str,tmpCorpus)))\n",
    "            currentTextCorpus=newCorpus\n",
    "            \"\"\"\n",
    "            tfidf = tfidf_vectorizer.fit_transform(currentTextCorpus)\n",
    "            \n",
    "            #print(\"\\n\"+course)\n",
    "            #print(\"\\n Количество отзывов: \"+str(responsesNum))\n",
    "            \"\"\"\n",
    "            t0 = time()\n",
    "            nmf = NMF(n_components=3).fit(tfidf)  \n",
    "            nmftime+=(time() - t0)\n",
    "            \n",
    "            #print(\"\\nTopics in NMF model:\")\n",
    "                       \n",
    "            #print_top_words(nmf, tfidf_feature_names, n_top_words)\n",
    "            \n",
    "            t0 = time()            \n",
    "            lda = LatentDirichletAllocation(n_components=3).fit(tfidf)     \n",
    "            ldatime+=(time() - t0)\n",
    "            #print(\"\\nTopics in LDA model:\")            \n",
    "            #print_top_words(lda, tfidf_feature_names, n_top_words)\n",
    "            \"\"\"\n",
    "            #t0 = time()   \n",
    "            svd = TruncatedSVD(n_components=3).fit(tfidf)   \n",
    "            #svdtime+=(time() - t0)\n",
    "            #print(\"\\nTopics in SVD model:\")\n",
    "            tfidf_feature_names = tfidf_vectorizer.get_feature_names()             \n",
    "            textres = textres.append({'курс': course,'поле':textField,'количество отзывов':responsesNum,'темы': print_top_words(svd, tfidf_feature_names, n_top_words)}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"done in %0.10fs.\" % nmftime)\\nprint(\"done in %0.10fs.\" % ldatime)\\nprint(\"done in %0.10fs.\" % svdtime)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(\"done in %0.10fs.\" % nmftime)\n",
    "print(\"done in %0.10fs.\" % ldatime)\n",
    "print(\"done in %0.10fs.\" % svdtime)\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "behavior in groups.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
